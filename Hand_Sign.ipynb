{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_Sign.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumya296/Deep_learning/blob/master/Hand_Sign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tck-_LR-FgYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#essential_libraries\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "\n",
        "#Deep learning framework\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Dense , Conv2D , Flatten ,MaxPool2D"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi0ZG7CeFyoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aa878905-2eca-44f5-c4d4-3ac7cf9a6257"
      },
      "source": [
        "\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hufqb9JJG76O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "addd09ae-dc42-4734-dd37-ae5a96b97c3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAZ1wD1PG9bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8ec6c3b7-c4b4-4d77-ff0f-5cf77a97da09"
      },
      "source": [
        "%cd /content/drive/My Drive/Projects\n",
        "os.getcwd()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Projects\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Projects'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvSFHBlOHQhd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3d64935-70b4-455c-af87-5357e122bd56"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My_model.h5py  sign_mnist_test.csv  sign_mnist_train.csv  training_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEQWbof-4X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -q pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImhI5ITrHT9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHizbQihf-hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_best_only = True,\n",
        "                                                 verbose=1)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyhOiAmJHlCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5a66a824-b5a9-4ce3-e97f-01dcdba0be71"
      },
      "source": [
        "def get_data(filename):\n",
        "    with open(filename) as training_file:\n",
        "        csv_reader = csv.reader(training_file, delimiter=',')\n",
        "        first_line = True\n",
        "        temp_images = []\n",
        "        temp_labels = []\n",
        "        for row in csv_reader:\n",
        "            if first_line:\n",
        "                # print(\"Ignoring first line\")\n",
        "                first_line = False\n",
        "            else:\n",
        "                temp_labels.append(row[0])\n",
        "                image_data = row[1:785]\n",
        "                image_data_as_array = np.array_split(image_data, 28)\n",
        "                temp_images.append(image_data_as_array)\n",
        "        images = np.array(temp_images).astype('float')\n",
        "        labels = np.array(temp_labels).astype('float')\n",
        "    return images, labels\n",
        "\n",
        "training_images, training_labels = get_data('sign_mnist_train.csv')\n",
        "testing_images, testing_labels = get_data('sign_mnist_test.csv')\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 28, 28)\n",
            "(27455,)\n",
            "(7172, 28, 28)\n",
            "(7172,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDuAwQoHw1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5876c996-0c2c-43a2-b79a-74f5842af8b8"
      },
      "source": [
        "training_images = np.expand_dims(training_images, axis=3)\n",
        "testing_images = np.expand_dims(testing_images, axis=3)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255)\n",
        "\n",
        "print(training_images.shape)\n",
        "print(testing_images.shape)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27455, 28, 28, 1)\n",
            "(7172, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyVj8g-FpACV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "17b49df2-2a93-4e10-b970-7d9c848d5663"
      },
      "source": [
        "plt.imshow(training_images[51].reshape((28,28)),cmap ='gray')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7529b731d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK9xP9oEmRGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_gen = train_datagen.flow(training_images, training_labels, batch_size=32)\n",
        "validation_gen=validation_datagen.flow(testing_images, testing_labels, batch_size=32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Z-F9FHJHPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "459f0c37-a2d7-4e50-a0b6-ae3a6bf553b3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu, kernel_initializer = 'he_normal',use_bias = False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu, kernel_initializer = 'he_normal',use_bias = False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation=tf.nn.relu, kernel_initializer = 'he_normal',use_bias = False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(26, activation=tf.nn.softmax)])\n",
        "\n",
        "# Compile Model. \n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.001),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit_generator(training_gen,\n",
        "                              steps_per_epoch=len(training_images) / 32,\n",
        "                              epochs=150,\n",
        "                              validation_data = validation_gen,\n",
        "                              validation_steps=len(testing_images) / 32,\n",
        "                              callbacks = [cp_callback])\n",
        "\n",
        "# training_images = training_images/255\n",
        "testing_images = testing_images/255\n",
        "# history = model.fit(x=training_images,y=training_labels,epochs = 150,batch_size = 32,validation_data = (testing_images,testing_labels))\n",
        "model.evaluate(testing_images, testing_labels)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-cc41b6301cb7>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 2.7405 - accuracy: 0.1793\n",
            "Epoch 00001: val_loss improved from inf to 3.74876, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 12s 14ms/step - loss: 2.7384 - accuracy: 0.1797 - val_loss: 3.7488 - val_accuracy: 0.1520\n",
            "Epoch 2/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 1.9878 - accuracy: 0.3597\n",
            "Epoch 00002: val_loss improved from 3.74876 to 1.19013, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 1.9878 - accuracy: 0.3597 - val_loss: 1.1901 - val_accuracy: 0.5929\n",
            "Epoch 3/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 1.6502 - accuracy: 0.4600\n",
            "Epoch 00003: val_loss improved from 1.19013 to 0.97372, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 1.6502 - accuracy: 0.4600 - val_loss: 0.9737 - val_accuracy: 0.6199\n",
            "Epoch 4/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 1.4395 - accuracy: 0.5206\n",
            "Epoch 00004: val_loss did not improve from 0.97372\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 1.4395 - accuracy: 0.5206 - val_loss: 1.4635 - val_accuracy: 0.5438\n",
            "Epoch 5/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 1.2880 - accuracy: 0.5717\n",
            "Epoch 00005: val_loss did not improve from 0.97372\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 1.2883 - accuracy: 0.5714 - val_loss: 3.5705 - val_accuracy: 0.2821\n",
            "Epoch 6/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 1.2039 - accuracy: 0.5981\n",
            "Epoch 00006: val_loss did not improve from 0.97372\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 1.2034 - accuracy: 0.5982 - val_loss: 1.0467 - val_accuracy: 0.6201\n",
            "Epoch 7/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 1.1087 - accuracy: 0.6277\n",
            "Epoch 00007: val_loss improved from 0.97372 to 0.75606, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 1.1085 - accuracy: 0.6277 - val_loss: 0.7561 - val_accuracy: 0.7151\n",
            "Epoch 8/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 1.0495 - accuracy: 0.6455\n",
            "Epoch 00008: val_loss did not improve from 0.75606\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 1.0498 - accuracy: 0.6453 - val_loss: 1.0147 - val_accuracy: 0.6675\n",
            "Epoch 9/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 1.0058 - accuracy: 0.6597\n",
            "Epoch 00009: val_loss improved from 0.75606 to 0.71061, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 1.0058 - accuracy: 0.6599 - val_loss: 0.7106 - val_accuracy: 0.7593\n",
            "Epoch 10/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.9652 - accuracy: 0.6750\n",
            "Epoch 00010: val_loss improved from 0.71061 to 0.51680, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.9649 - accuracy: 0.6752 - val_loss: 0.5168 - val_accuracy: 0.8105\n",
            "Epoch 11/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.9114 - accuracy: 0.6957\n",
            "Epoch 00011: val_loss improved from 0.51680 to 0.49558, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.9114 - accuracy: 0.6957 - val_loss: 0.4956 - val_accuracy: 0.8132\n",
            "Epoch 12/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.8927 - accuracy: 0.7025\n",
            "Epoch 00012: val_loss did not improve from 0.49558\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.8927 - accuracy: 0.7025 - val_loss: 0.6381 - val_accuracy: 0.7429\n",
            "Epoch 13/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.8575 - accuracy: 0.7094\n",
            "Epoch 00013: val_loss improved from 0.49558 to 0.34891, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.8573 - accuracy: 0.7095 - val_loss: 0.3489 - val_accuracy: 0.8719\n",
            "Epoch 14/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.8288 - accuracy: 0.7201\n",
            "Epoch 00014: val_loss did not improve from 0.34891\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.8289 - accuracy: 0.7200 - val_loss: 0.5518 - val_accuracy: 0.7853\n",
            "Epoch 15/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.7980 - accuracy: 0.7300\n",
            "Epoch 00015: val_loss did not improve from 0.34891\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.7983 - accuracy: 0.7300 - val_loss: 0.7966 - val_accuracy: 0.7478\n",
            "Epoch 16/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.7872 - accuracy: 0.7339\n",
            "Epoch 00016: val_loss did not improve from 0.34891\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.7870 - accuracy: 0.7340 - val_loss: 0.3530 - val_accuracy: 0.8634\n",
            "Epoch 17/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.7706 - accuracy: 0.7417\n",
            "Epoch 00017: val_loss improved from 0.34891 to 0.34609, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.7705 - accuracy: 0.7417 - val_loss: 0.3461 - val_accuracy: 0.8737\n",
            "Epoch 18/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.7467 - accuracy: 0.7510\n",
            "Epoch 00018: val_loss did not improve from 0.34609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.7465 - accuracy: 0.7509 - val_loss: 0.8924 - val_accuracy: 0.7052\n",
            "Epoch 19/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.7236 - accuracy: 0.7578\n",
            "Epoch 00019: val_loss did not improve from 0.34609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.7244 - accuracy: 0.7575 - val_loss: 0.3717 - val_accuracy: 0.8723\n",
            "Epoch 20/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.7626\n",
            "Epoch 00020: val_loss improved from 0.34609 to 0.30848, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.7068 - accuracy: 0.7626 - val_loss: 0.3085 - val_accuracy: 0.8766\n",
            "Epoch 21/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.7045 - accuracy: 0.7606\n",
            "Epoch 00021: val_loss improved from 0.30848 to 0.19491, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.7045 - accuracy: 0.7606 - val_loss: 0.1949 - val_accuracy: 0.9288\n",
            "Epoch 22/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.7718\n",
            "Epoch 00022: val_loss did not improve from 0.19491\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.6826 - accuracy: 0.7719 - val_loss: 0.3679 - val_accuracy: 0.8794\n",
            "Epoch 23/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.7739\n",
            "Epoch 00023: val_loss did not improve from 0.19491\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.6764 - accuracy: 0.7739 - val_loss: 0.4503 - val_accuracy: 0.8529\n",
            "Epoch 24/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.6587 - accuracy: 0.7808\n",
            "Epoch 00024: val_loss improved from 0.19491 to 0.18384, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.6580 - accuracy: 0.7811 - val_loss: 0.1838 - val_accuracy: 0.9359\n",
            "Epoch 25/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.6463 - accuracy: 0.7841\n",
            "Epoch 00025: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.6467 - accuracy: 0.7838 - val_loss: 0.3075 - val_accuracy: 0.8826\n",
            "Epoch 26/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.6455 - accuracy: 0.7867\n",
            "Epoch 00026: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.6452 - accuracy: 0.7867 - val_loss: 0.3085 - val_accuracy: 0.8970\n",
            "Epoch 27/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.7859\n",
            "Epoch 00027: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.6369 - accuracy: 0.7859 - val_loss: 0.4161 - val_accuracy: 0.8620\n",
            "Epoch 28/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.6241 - accuracy: 0.7895\n",
            "Epoch 00028: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.6239 - accuracy: 0.7897 - val_loss: 0.6891 - val_accuracy: 0.7617\n",
            "Epoch 29/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.7935\n",
            "Epoch 00029: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.6156 - accuracy: 0.7935 - val_loss: 0.3478 - val_accuracy: 0.8728\n",
            "Epoch 30/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.7979\n",
            "Epoch 00030: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 0.6059 - accuracy: 0.7980 - val_loss: 0.2480 - val_accuracy: 0.9127\n",
            "Epoch 31/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.5915 - accuracy: 0.8022\n",
            "Epoch 00031: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.5916 - accuracy: 0.8023 - val_loss: 0.3780 - val_accuracy: 0.8680\n",
            "Epoch 32/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.8016\n",
            "Epoch 00032: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.5882 - accuracy: 0.8016 - val_loss: 0.2589 - val_accuracy: 0.9124\n",
            "Epoch 33/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.5799 - accuracy: 0.8046\n",
            "Epoch 00033: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 0.5798 - accuracy: 0.8047 - val_loss: 0.2518 - val_accuracy: 0.9034\n",
            "Epoch 34/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.8071\n",
            "Epoch 00034: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5761 - accuracy: 0.8069 - val_loss: 0.2735 - val_accuracy: 0.9014\n",
            "Epoch 35/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.8137\n",
            "Epoch 00035: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.5657 - accuracy: 0.8137 - val_loss: 0.4474 - val_accuracy: 0.8463\n",
            "Epoch 36/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.5589 - accuracy: 0.8146\n",
            "Epoch 00036: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5588 - accuracy: 0.8146 - val_loss: 0.3355 - val_accuracy: 0.8911\n",
            "Epoch 37/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.5578 - accuracy: 0.8163\n",
            "Epoch 00037: val_loss did not improve from 0.18384\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5570 - accuracy: 0.8166 - val_loss: 0.2120 - val_accuracy: 0.9169\n",
            "Epoch 38/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.8216\n",
            "Epoch 00038: val_loss improved from 0.18384 to 0.18110, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5385 - accuracy: 0.8216 - val_loss: 0.1811 - val_accuracy: 0.9359\n",
            "Epoch 39/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.8181\n",
            "Epoch 00039: val_loss did not improve from 0.18110\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5476 - accuracy: 0.8181 - val_loss: 0.2475 - val_accuracy: 0.9130\n",
            "Epoch 40/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.8218\n",
            "Epoch 00040: val_loss did not improve from 0.18110\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5373 - accuracy: 0.8218 - val_loss: 0.3475 - val_accuracy: 0.8719\n",
            "Epoch 41/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.8280\n",
            "Epoch 00041: val_loss improved from 0.18110 to 0.11705, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5224 - accuracy: 0.8280 - val_loss: 0.1171 - val_accuracy: 0.9697\n",
            "Epoch 42/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.8293\n",
            "Epoch 00042: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5228 - accuracy: 0.8292 - val_loss: 0.2140 - val_accuracy: 0.9207\n",
            "Epoch 43/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.8244\n",
            "Epoch 00043: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.5287 - accuracy: 0.8244 - val_loss: 0.1367 - val_accuracy: 0.9547\n",
            "Epoch 44/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.5255 - accuracy: 0.8268\n",
            "Epoch 00044: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5254 - accuracy: 0.8268 - val_loss: 0.6075 - val_accuracy: 0.7882\n",
            "Epoch 45/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.5131 - accuracy: 0.8298\n",
            "Epoch 00045: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5131 - accuracy: 0.8298 - val_loss: 0.7688 - val_accuracy: 0.7566\n",
            "Epoch 46/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.5025 - accuracy: 0.8334\n",
            "Epoch 00046: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.5019 - accuracy: 0.8336 - val_loss: 0.1461 - val_accuracy: 0.9628\n",
            "Epoch 47/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.8307\n",
            "Epoch 00047: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.5142 - accuracy: 0.8306 - val_loss: 0.1809 - val_accuracy: 0.9393\n",
            "Epoch 48/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.8342\n",
            "Epoch 00048: val_loss did not improve from 0.11705\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4992 - accuracy: 0.8342 - val_loss: 0.2030 - val_accuracy: 0.9395\n",
            "Epoch 49/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.4918 - accuracy: 0.8371\n",
            "Epoch 00049: val_loss improved from 0.11705 to 0.11337, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4919 - accuracy: 0.8369 - val_loss: 0.1134 - val_accuracy: 0.9656\n",
            "Epoch 50/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.8369\n",
            "Epoch 00050: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4871 - accuracy: 0.8367 - val_loss: 0.2306 - val_accuracy: 0.9275\n",
            "Epoch 51/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.4878 - accuracy: 0.8407\n",
            "Epoch 00051: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4879 - accuracy: 0.8408 - val_loss: 0.3652 - val_accuracy: 0.8865\n",
            "Epoch 52/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.8408\n",
            "Epoch 00052: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4841 - accuracy: 0.8409 - val_loss: 0.1947 - val_accuracy: 0.9248\n",
            "Epoch 53/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4819 - accuracy: 0.8396\n",
            "Epoch 00053: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4817 - accuracy: 0.8396 - val_loss: 0.2114 - val_accuracy: 0.9239\n",
            "Epoch 54/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4816 - accuracy: 0.8415\n",
            "Epoch 00054: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4818 - accuracy: 0.8414 - val_loss: 0.1578 - val_accuracy: 0.9417\n",
            "Epoch 55/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.8478\n",
            "Epoch 00055: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4695 - accuracy: 0.8478 - val_loss: 0.2047 - val_accuracy: 0.9257\n",
            "Epoch 56/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.8454\n",
            "Epoch 00056: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4648 - accuracy: 0.8453 - val_loss: 0.1415 - val_accuracy: 0.9476\n",
            "Epoch 57/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.4609 - accuracy: 0.8494\n",
            "Epoch 00057: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4607 - accuracy: 0.8495 - val_loss: 0.1236 - val_accuracy: 0.9603\n",
            "Epoch 58/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4595 - accuracy: 0.8494\n",
            "Epoch 00058: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4595 - accuracy: 0.8494 - val_loss: 0.2730 - val_accuracy: 0.8940\n",
            "Epoch 59/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8492\n",
            "Epoch 00059: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 11s 13ms/step - loss: 0.4533 - accuracy: 0.8492 - val_loss: 0.1558 - val_accuracy: 0.9469\n",
            "Epoch 60/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.8457\n",
            "Epoch 00060: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4623 - accuracy: 0.8456 - val_loss: 0.3341 - val_accuracy: 0.8926\n",
            "Epoch 61/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4520 - accuracy: 0.8504\n",
            "Epoch 00061: val_loss did not improve from 0.11337\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4519 - accuracy: 0.8504 - val_loss: 0.1273 - val_accuracy: 0.9564\n",
            "Epoch 62/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.4484 - accuracy: 0.8538\n",
            "Epoch 00062: val_loss improved from 0.11337 to 0.09609, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4483 - accuracy: 0.8540 - val_loss: 0.0961 - val_accuracy: 0.9642\n",
            "Epoch 63/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4506 - accuracy: 0.8533\n",
            "Epoch 00063: val_loss did not improve from 0.09609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4506 - accuracy: 0.8533 - val_loss: 0.1047 - val_accuracy: 0.9636\n",
            "Epoch 64/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4447 - accuracy: 0.8542\n",
            "Epoch 00064: val_loss did not improve from 0.09609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4447 - accuracy: 0.8542 - val_loss: 0.2381 - val_accuracy: 0.9221\n",
            "Epoch 65/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4421 - accuracy: 0.8566\n",
            "Epoch 00065: val_loss did not improve from 0.09609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4421 - accuracy: 0.8566 - val_loss: 0.1712 - val_accuracy: 0.9453\n",
            "Epoch 66/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8568\n",
            "Epoch 00066: val_loss did not improve from 0.09609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4374 - accuracy: 0.8568 - val_loss: 0.1964 - val_accuracy: 0.9260\n",
            "Epoch 67/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.4360 - accuracy: 0.8558\n",
            "Epoch 00067: val_loss did not improve from 0.09609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4364 - accuracy: 0.8558 - val_loss: 0.3872 - val_accuracy: 0.8763\n",
            "Epoch 68/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.8568\n",
            "Epoch 00068: val_loss did not improve from 0.09609\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4331 - accuracy: 0.8570 - val_loss: 0.0997 - val_accuracy: 0.9594\n",
            "Epoch 69/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.8539\n",
            "Epoch 00069: val_loss improved from 0.09609 to 0.08099, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4347 - accuracy: 0.8539 - val_loss: 0.0810 - val_accuracy: 0.9741\n",
            "Epoch 70/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.8560\n",
            "Epoch 00070: val_loss did not improve from 0.08099\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4389 - accuracy: 0.8559 - val_loss: 0.1321 - val_accuracy: 0.9499\n",
            "Epoch 71/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4239 - accuracy: 0.8627\n",
            "Epoch 00071: val_loss did not improve from 0.08099\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4239 - accuracy: 0.8627 - val_loss: 0.1172 - val_accuracy: 0.9603\n",
            "Epoch 72/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.4142 - accuracy: 0.8643\n",
            "Epoch 00072: val_loss did not improve from 0.08099\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4144 - accuracy: 0.8643 - val_loss: 0.1070 - val_accuracy: 0.9607\n",
            "Epoch 73/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.8615\n",
            "Epoch 00073: val_loss improved from 0.08099 to 0.06689, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4216 - accuracy: 0.8615 - val_loss: 0.0669 - val_accuracy: 0.9750\n",
            "Epoch 74/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4202 - accuracy: 0.8605\n",
            "Epoch 00074: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4200 - accuracy: 0.8606 - val_loss: 0.1144 - val_accuracy: 0.9626\n",
            "Epoch 75/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8647\n",
            "Epoch 00075: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4108 - accuracy: 0.8646 - val_loss: 0.2068 - val_accuracy: 0.9267\n",
            "Epoch 76/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4160 - accuracy: 0.8640\n",
            "Epoch 00076: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4160 - accuracy: 0.8640 - val_loss: 0.1584 - val_accuracy: 0.9516\n",
            "Epoch 77/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8623\n",
            "Epoch 00077: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4209 - accuracy: 0.8623 - val_loss: 0.2052 - val_accuracy: 0.9335\n",
            "Epoch 78/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8650\n",
            "Epoch 00078: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4130 - accuracy: 0.8650 - val_loss: 0.1602 - val_accuracy: 0.9412\n",
            "Epoch 79/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.4099 - accuracy: 0.8642\n",
            "Epoch 00079: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4098 - accuracy: 0.8642 - val_loss: 0.1138 - val_accuracy: 0.9582\n",
            "Epoch 80/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.4088 - accuracy: 0.8665\n",
            "Epoch 00080: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4087 - accuracy: 0.8665 - val_loss: 0.2812 - val_accuracy: 0.8968\n",
            "Epoch 81/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.8661\n",
            "Epoch 00081: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.4076 - accuracy: 0.8661 - val_loss: 0.2307 - val_accuracy: 0.9320\n",
            "Epoch 82/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8706\n",
            "Epoch 00082: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3976 - accuracy: 0.8706 - val_loss: 0.0788 - val_accuracy: 0.9710\n",
            "Epoch 83/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3969 - accuracy: 0.8692\n",
            "Epoch 00083: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3969 - accuracy: 0.8692 - val_loss: 0.1861 - val_accuracy: 0.9354\n",
            "Epoch 84/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3982 - accuracy: 0.8700\n",
            "Epoch 00084: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3984 - accuracy: 0.8701 - val_loss: 0.1214 - val_accuracy: 0.9561\n",
            "Epoch 85/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3921 - accuracy: 0.8723\n",
            "Epoch 00085: val_loss did not improve from 0.06689\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3922 - accuracy: 0.8722 - val_loss: 0.2154 - val_accuracy: 0.9247\n",
            "Epoch 86/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3861 - accuracy: 0.8709\n",
            "Epoch 00086: val_loss improved from 0.06689 to 0.06120, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3860 - accuracy: 0.8710 - val_loss: 0.0612 - val_accuracy: 0.9801\n",
            "Epoch 87/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3935 - accuracy: 0.8723\n",
            "Epoch 00087: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3940 - accuracy: 0.8722 - val_loss: 0.1083 - val_accuracy: 0.9622\n",
            "Epoch 88/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8701\n",
            "Epoch 00088: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3905 - accuracy: 0.8702 - val_loss: 0.0776 - val_accuracy: 0.9755\n",
            "Epoch 89/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3892 - accuracy: 0.8703\n",
            "Epoch 00089: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.3898 - accuracy: 0.8701 - val_loss: 0.0894 - val_accuracy: 0.9657\n",
            "Epoch 90/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3853 - accuracy: 0.8732\n",
            "Epoch 00090: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3852 - accuracy: 0.8731 - val_loss: 0.0793 - val_accuracy: 0.9720\n",
            "Epoch 91/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8732\n",
            "Epoch 00091: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3821 - accuracy: 0.8733 - val_loss: 0.1055 - val_accuracy: 0.9612\n",
            "Epoch 92/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8760\n",
            "Epoch 00092: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.3818 - accuracy: 0.8761 - val_loss: 0.1406 - val_accuracy: 0.9527\n",
            "Epoch 93/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8742\n",
            "Epoch 00093: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3842 - accuracy: 0.8743 - val_loss: 0.1062 - val_accuracy: 0.9639\n",
            "Epoch 94/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3767 - accuracy: 0.8774\n",
            "Epoch 00094: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3764 - accuracy: 0.8774 - val_loss: 0.0905 - val_accuracy: 0.9683\n",
            "Epoch 95/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.8744\n",
            "Epoch 00095: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3846 - accuracy: 0.8744 - val_loss: 0.2467 - val_accuracy: 0.9013\n",
            "Epoch 96/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8748\n",
            "Epoch 00096: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3827 - accuracy: 0.8750 - val_loss: 0.1282 - val_accuracy: 0.9601\n",
            "Epoch 97/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8770\n",
            "Epoch 00097: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3796 - accuracy: 0.8769 - val_loss: 0.0914 - val_accuracy: 0.9725\n",
            "Epoch 98/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.8780\n",
            "Epoch 00098: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3746 - accuracy: 0.8779 - val_loss: 0.1595 - val_accuracy: 0.9382\n",
            "Epoch 99/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8743\n",
            "Epoch 00099: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3765 - accuracy: 0.8744 - val_loss: 0.1659 - val_accuracy: 0.9449\n",
            "Epoch 100/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3665 - accuracy: 0.8795\n",
            "Epoch 00100: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3665 - accuracy: 0.8796 - val_loss: 0.2008 - val_accuracy: 0.9246\n",
            "Epoch 101/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3727 - accuracy: 0.8784\n",
            "Epoch 00101: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3727 - accuracy: 0.8784 - val_loss: 0.1233 - val_accuracy: 0.9562\n",
            "Epoch 102/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8814\n",
            "Epoch 00102: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3693 - accuracy: 0.8816 - val_loss: 0.0648 - val_accuracy: 0.9731\n",
            "Epoch 103/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3635 - accuracy: 0.8810\n",
            "Epoch 00103: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3637 - accuracy: 0.8809 - val_loss: 0.1139 - val_accuracy: 0.9607\n",
            "Epoch 104/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3761 - accuracy: 0.8767\n",
            "Epoch 00104: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3764 - accuracy: 0.8766 - val_loss: 0.0858 - val_accuracy: 0.9657\n",
            "Epoch 105/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.8801\n",
            "Epoch 00105: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3652 - accuracy: 0.8802 - val_loss: 0.1201 - val_accuracy: 0.9644\n",
            "Epoch 106/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8803\n",
            "Epoch 00106: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3677 - accuracy: 0.8801 - val_loss: 0.0706 - val_accuracy: 0.9748\n",
            "Epoch 107/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.8836\n",
            "Epoch 00107: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3572 - accuracy: 0.8837 - val_loss: 0.0662 - val_accuracy: 0.9782\n",
            "Epoch 108/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3586 - accuracy: 0.8819\n",
            "Epoch 00108: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3587 - accuracy: 0.8819 - val_loss: 0.0757 - val_accuracy: 0.9755\n",
            "Epoch 109/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.8804\n",
            "Epoch 00109: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3602 - accuracy: 0.8805 - val_loss: 0.1183 - val_accuracy: 0.9589\n",
            "Epoch 110/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8815\n",
            "Epoch 00110: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3583 - accuracy: 0.8816 - val_loss: 0.1150 - val_accuracy: 0.9626\n",
            "Epoch 111/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.8846\n",
            "Epoch 00111: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3529 - accuracy: 0.8846 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
            "Epoch 112/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8823\n",
            "Epoch 00112: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3578 - accuracy: 0.8823 - val_loss: 0.1357 - val_accuracy: 0.9491\n",
            "Epoch 113/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3637 - accuracy: 0.8812\n",
            "Epoch 00113: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3637 - accuracy: 0.8813 - val_loss: 0.2334 - val_accuracy: 0.9420\n",
            "Epoch 114/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3429 - accuracy: 0.8885\n",
            "Epoch 00114: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3429 - accuracy: 0.8884 - val_loss: 0.1279 - val_accuracy: 0.9603\n",
            "Epoch 115/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.8887\n",
            "Epoch 00115: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3505 - accuracy: 0.8886 - val_loss: 0.1545 - val_accuracy: 0.9497\n",
            "Epoch 116/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.8897\n",
            "Epoch 00116: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3404 - accuracy: 0.8898 - val_loss: 0.0774 - val_accuracy: 0.9709\n",
            "Epoch 117/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.8886\n",
            "Epoch 00117: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3462 - accuracy: 0.8887 - val_loss: 0.0710 - val_accuracy: 0.9769\n",
            "Epoch 118/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3521 - accuracy: 0.8857\n",
            "Epoch 00118: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3520 - accuracy: 0.8857 - val_loss: 0.0684 - val_accuracy: 0.9750\n",
            "Epoch 119/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3541 - accuracy: 0.8846\n",
            "Epoch 00119: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.3543 - accuracy: 0.8845 - val_loss: 0.0881 - val_accuracy: 0.9746\n",
            "Epoch 120/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3431 - accuracy: 0.8861\n",
            "Epoch 00120: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3430 - accuracy: 0.8861 - val_loss: 0.1274 - val_accuracy: 0.9555\n",
            "Epoch 121/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3388 - accuracy: 0.8906\n",
            "Epoch 00121: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3387 - accuracy: 0.8907 - val_loss: 0.1217 - val_accuracy: 0.9608\n",
            "Epoch 122/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.8889\n",
            "Epoch 00122: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3389 - accuracy: 0.8887 - val_loss: 0.1181 - val_accuracy: 0.9601\n",
            "Epoch 123/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.8900\n",
            "Epoch 00123: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3444 - accuracy: 0.8900 - val_loss: 0.0751 - val_accuracy: 0.9745\n",
            "Epoch 124/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8901\n",
            "Epoch 00124: val_loss did not improve from 0.06120\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3399 - accuracy: 0.8901 - val_loss: 0.1411 - val_accuracy: 0.9584\n",
            "Epoch 125/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8892\n",
            "Epoch 00125: val_loss improved from 0.06120 to 0.05829, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3419 - accuracy: 0.8892 - val_loss: 0.0583 - val_accuracy: 0.9803\n",
            "Epoch 126/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8890\n",
            "Epoch 00126: val_loss did not improve from 0.05829\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3388 - accuracy: 0.8888 - val_loss: 0.0908 - val_accuracy: 0.9717\n",
            "Epoch 127/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.8898\n",
            "Epoch 00127: val_loss did not improve from 0.05829\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3406 - accuracy: 0.8898 - val_loss: 0.0816 - val_accuracy: 0.9739\n",
            "Epoch 128/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.8912\n",
            "Epoch 00128: val_loss improved from 0.05829 to 0.05177, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3312 - accuracy: 0.8912 - val_loss: 0.0518 - val_accuracy: 0.9812\n",
            "Epoch 129/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3418 - accuracy: 0.8896\n",
            "Epoch 00129: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3418 - accuracy: 0.8896 - val_loss: 0.0783 - val_accuracy: 0.9753\n",
            "Epoch 130/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8921\n",
            "Epoch 00130: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3370 - accuracy: 0.8922 - val_loss: 0.0884 - val_accuracy: 0.9703\n",
            "Epoch 131/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3439 - accuracy: 0.8893\n",
            "Epoch 00131: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3438 - accuracy: 0.8894 - val_loss: 0.1134 - val_accuracy: 0.9579\n",
            "Epoch 132/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8907\n",
            "Epoch 00132: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3362 - accuracy: 0.8907 - val_loss: 0.1256 - val_accuracy: 0.9617\n",
            "Epoch 133/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8888\n",
            "Epoch 00133: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3368 - accuracy: 0.8889 - val_loss: 0.0693 - val_accuracy: 0.9760\n",
            "Epoch 134/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3322 - accuracy: 0.8918\n",
            "Epoch 00134: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3317 - accuracy: 0.8919 - val_loss: 0.0741 - val_accuracy: 0.9736\n",
            "Epoch 135/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.8942\n",
            "Epoch 00135: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3280 - accuracy: 0.8943 - val_loss: 0.0749 - val_accuracy: 0.9718\n",
            "Epoch 136/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8949\n",
            "Epoch 00136: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3251 - accuracy: 0.8946 - val_loss: 0.1134 - val_accuracy: 0.9586\n",
            "Epoch 137/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8913\n",
            "Epoch 00137: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3353 - accuracy: 0.8912 - val_loss: 0.0828 - val_accuracy: 0.9643\n",
            "Epoch 138/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3275 - accuracy: 0.8953\n",
            "Epoch 00138: val_loss did not improve from 0.05177\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3279 - accuracy: 0.8951 - val_loss: 0.1500 - val_accuracy: 0.9501\n",
            "Epoch 139/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8962\n",
            "Epoch 00139: val_loss improved from 0.05177 to 0.04475, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3219 - accuracy: 0.8962 - val_loss: 0.0447 - val_accuracy: 0.9865\n",
            "Epoch 140/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.8955\n",
            "Epoch 00140: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3221 - accuracy: 0.8956 - val_loss: 0.0658 - val_accuracy: 0.9750\n",
            "Epoch 141/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.8967\n",
            "Epoch 00141: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3183 - accuracy: 0.8966 - val_loss: 0.0989 - val_accuracy: 0.9728\n",
            "Epoch 142/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.8942\n",
            "Epoch 00142: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3269 - accuracy: 0.8942 - val_loss: 0.1736 - val_accuracy: 0.9275\n",
            "Epoch 143/150\n",
            "854/857 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8980\n",
            "Epoch 00143: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3252 - accuracy: 0.8980 - val_loss: 0.0966 - val_accuracy: 0.9663\n",
            "Epoch 144/150\n",
            "855/857 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8947\n",
            "Epoch 00144: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3243 - accuracy: 0.8944 - val_loss: 0.1592 - val_accuracy: 0.9513\n",
            "Epoch 145/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8942\n",
            "Epoch 00145: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3247 - accuracy: 0.8940 - val_loss: 0.1250 - val_accuracy: 0.9550\n",
            "Epoch 146/150\n",
            "858/857 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.8957\n",
            "Epoch 00146: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3212 - accuracy: 0.8957 - val_loss: 0.0986 - val_accuracy: 0.9689\n",
            "Epoch 147/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3152 - accuracy: 0.8951\n",
            "Epoch 00147: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3153 - accuracy: 0.8951 - val_loss: 0.0450 - val_accuracy: 0.9865\n",
            "Epoch 148/150\n",
            "857/857 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8968\n",
            "Epoch 00148: val_loss did not improve from 0.04475\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3207 - accuracy: 0.8969 - val_loss: 0.0655 - val_accuracy: 0.9757\n",
            "Epoch 149/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3169 - accuracy: 0.8983\n",
            "Epoch 00149: val_loss improved from 0.04475 to 0.04223, saving model to training_1/cp.ckpt\n",
            "858/857 [==============================] - 11s 12ms/step - loss: 0.3166 - accuracy: 0.8984 - val_loss: 0.0422 - val_accuracy: 0.9888\n",
            "Epoch 150/150\n",
            "856/857 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8981\n",
            "Epoch 00150: val_loss did not improve from 0.04223\n",
            "858/857 [==============================] - 10s 12ms/step - loss: 0.3109 - accuracy: 0.8981 - val_loss: 0.0723 - val_accuracy: 0.9803\n",
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0723 - accuracy: 0.9803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07230984419584274, 0.9803401827812195]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tolv_UfqJ6zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d2ee79e-c70f-4a32-b127-74ceccb5933d"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f75297987b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15GIqpA7LAaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "998ef19a-4690-46de-f42d-81b9b7b7fcf1"
      },
      "source": [
        "model.evaluate(testing_images,testing_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04222554713487625, 0.9888455271720886]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ1hNKFPvXq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "55e58ec1-85fb-4944-abd2-99bf4f493b0e"
      },
      "source": [
        "model.save('My_model.h5py')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: My_model.h5py/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufhd0yjj2Akp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "5f57ebca-f0a8-4f59-be47-0ae66a504cc0"
      },
      "source": [
        "model_temp = keras.models.load_model('My_model.h5py')\n",
        "model_temp.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32768     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8192      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 26)                1690      \n",
            "=================================================================\n",
            "Total params: 938,138\n",
            "Trainable params: 937,242\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM0CGIupBCjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}